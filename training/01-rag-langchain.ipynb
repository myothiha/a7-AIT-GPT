{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "# Retrieval-Augmented generation (RAG)\n",
    "\n",
    "RAG is a technique for augmenting LLM knowledge with additional, often private or real-time, data.\n",
    "\n",
    "LLMs can reason about wide-ranging topics, but their knowledge is limited to the public data up to a specific point in time that they were trained on. If you want to build AI applications that can reason about private data or data introduced after a model’s cutoff date, you need to augment the knowledge of the model with the specific information it needs.\n",
    "\n",
    "<img src=\"../figures/RAG-process.png\" >\n",
    "\n",
    "Introducing `ChakyBot`, an innovative chatbot designed to assist Chaky (the instructor) and TA (Gun) in explaining the lesson of the NLP course to students. Leveraging LangChain technology, ChakyBot excels in retrieving information from documents, ensuring a seamless and efficient learning experience for students engaging with the NLP curriculum.\n",
    "\n",
    "1. Prompt\n",
    "2. Retrieval\n",
    "3. Memory\n",
    "4. Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.0.350 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (0.0.350)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from langchain==0.0.350) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from langchain==0.0.350) (1.4.52)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from langchain==0.0.350) (3.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from langchain==0.0.350) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from langchain==0.0.350) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from langchain==0.0.350) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from langchain==0.0.350) (0.0.20)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from langchain==0.0.350) (0.1.23)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from langchain==0.0.350) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from langchain==0.0.350) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from langchain==0.0.350) (2.6.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from langchain==0.0.350) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from langchain==0.0.350) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.350) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.350) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.350) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1->langchain==0.0.350) (4.3.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1->langchain==0.0.350) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from pydantic<3,>=1->langchain==0.0.350) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from pydantic<3,>=1->langchain==0.0.350) (2.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from pydantic<3,>=1->langchain==0.0.350) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.0.350) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.0.350) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.0.350) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.0.350) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.350) (3.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain==0.0.350) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain==0.0.350) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.350) (1.0.0)\n",
      "Requirement already satisfied: accelerate==0.25.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from accelerate==0.25.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from accelerate==0.25.0) (23.2)\n",
      "Requirement already satisfied: psutil in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from accelerate==0.25.0) (5.9.7)\n",
      "Requirement already satisfied: pyyaml in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from accelerate==0.25.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from accelerate==0.25.0) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from accelerate==0.25.0) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from accelerate==0.25.0) (0.4.2)\n",
      "Requirement already satisfied: filelock in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0) (2023.10.0)\n",
      "Requirement already satisfied: requests in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from huggingface-hub->accelerate==0.25.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from huggingface-hub->accelerate==0.25.0) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate==0.25.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate==0.25.0) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate==0.25.0) (1.3.0)\n",
      "Requirement already satisfied: transformers==4.36.2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (4.36.2)\n",
      "Requirement already satisfied: filelock in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from transformers==4.36.2) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from transformers==4.36.2) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from transformers==4.36.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from transformers==4.36.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from transformers==4.36.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from transformers==4.36.2) (2023.12.25)\n",
      "Requirement already satisfied: requests in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from transformers==4.36.2) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from transformers==4.36.2) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from transformers==4.36.2) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from transformers==4.36.2) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from requests->transformers==4.36.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from requests->transformers==4.36.2) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from requests->transformers==4.36.2) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from requests->transformers==4.36.2) (2024.2.2)\n",
      "Requirement already satisfied: bitsandbytes==0.41.2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (0.41.2)\n",
      "Requirement already satisfied: sentence-transformers==2.2.2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (4.36.2)\n",
      "Requirement already satisfied: tqdm in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (2.1.2)\n",
      "Requirement already satisfied: torchvision in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (0.16.2)\n",
      "Requirement already satisfied: numpy in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (1.4.0)\n",
      "Requirement already satisfied: scipy in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (1.12.0)\n",
      "Requirement already satisfied: nltk in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from sentence-transformers==2.2.2) (0.20.3)\n",
      "Requirement already satisfied: filelock in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.10.0)\n",
      "Requirement already satisfied: requests in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (23.2)\n",
      "Requirement already satisfied: sympy in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.4.2)\n",
      "Requirement already satisfied: click in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from nltk->sentence-transformers==2.2.2) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from torchvision->sentence-transformers==2.2.2) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
      "Requirement already satisfied: InstructorEmbedding==1.0.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (1.0.1)\n",
      "Requirement already satisfied: pymupdf==1.23.8 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (1.23.8)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.7 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from pymupdf==1.23.8) (1.23.7)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu==1.7.2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu==1.7.2\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: faiss-cpu==1.7.4 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (1.7.4)\n"
     ]
    }
   ],
   "source": [
    "#langchain library\n",
    "!pip3 install langchain==0.1.0\n",
    "#LLM\n",
    "!pip3 install accelerate==0.25.0\n",
    "!pip3 install transformers==4.36.2\n",
    "!pip3 install bitsandbytes==0.41.2\n",
    "#Text Embedding\n",
    "!pip3 install sentence-transformers==2.2.2\n",
    "!pip3 install InstructorEmbedding==1.0.1\n",
    "#vectorstore\n",
    "!pip3 install pymupdf==1.23.8\n",
    "!pip3 install faiss-gpu==1.7.2\n",
    "!pip3 install faiss-cpu==1.7.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "# Set GPU device\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "# os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prompt\n",
    "\n",
    "A set of instructions or input provided by a user to guide the model's response, helping it understand the context and generate relevant and coherent language-based output, such as answering questions, completing sentences, or engaging in a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template=\"I'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \\n    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it's about probabilistic models, language models, or any other related topic, \\n    I'm here to help break down complex concepts into easy-to-understand explanations.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "    I'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \n",
    "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
    "    Whether it's about probabilistic models, language models, or any other related topic, \n",
    "    I'm here to help break down complex concepts into easy-to-understand explanations.\n",
    "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    Answer:\n",
    "    \"\"\".strip()\n",
    "\n",
    "PROMPT = PromptTemplate.from_template(\n",
    "    template = prompt_template\n",
    ")\n",
    "\n",
    "PROMPT\n",
    "#using str.format \n",
    "#The placeholder is defined using curly brackets: {} {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \\n    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it's about probabilistic models, language models, or any other related topic, \\n    I'm here to help break down complex concepts into easy-to-understand explanations.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions.\\n    Question: What is Machine Learning\\n    Answer:\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT.format(\n",
    "    context = \"Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions.\",\n",
    "    question = \"What is Machine Learning\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : [How to improve prompting (Zero-shot, Few-shot, Chain-of-Thought, etc.](https://github.com/chaklam-silpasuwanchai/Natural-Language-Processing/blob/main/Code/05%20-%20RAG/advance/cot-tot-prompting.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieval\n",
    "\n",
    "1. `Document loaders` : Load documents from many different sources (HTML, PDF, code). \n",
    "2. `Document transformers` : One of the essential steps in document retrieval is breaking down a large document into smaller, relevant chunks to enhance the retrieval process.\n",
    "3. `Text embedding models` : Embeddings capture the semantic meaning of the text, allowing you to quickly and efficiently find other pieces of text that are similar.\n",
    "4. `Vector stores`: there has emerged a need for databases to support efficient storage and searching of these embeddings.\n",
    "5. `Retrievers` : Once the data is in the database, you still need to retrieve it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Document Loaders \n",
    "Use document loaders to load data from a source as Document's. A Document is a piece of text and associated metadata. For example, there are document loaders for loading a simple .txt file, for loading the text contents of any web page, or even for loading a transcript of a YouTube video.\n",
    "\n",
    "[PDF Loader](https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf)\n",
    "\n",
    "[Download Document](https://web.stanford.edu/~jurafsky/slp3/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (0.12.6)\n",
      "Requirement already satisfied: backoff==2.2.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: beautifulsoup4==4.12.3 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (4.12.3)\n",
      "Requirement already satisfied: certifi==2024.2.2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (2024.2.2)\n",
      "Requirement already satisfied: chardet==5.2.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (3.3.2)\n",
      "Requirement already satisfied: click==8.1.7 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (8.1.7)\n",
      "Requirement already satisfied: dataclasses-json==0.6.4 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (0.6.4)\n",
      "Requirement already satisfied: dataclasses-json-speakeasy==0.5.11 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (0.5.11)\n",
      "Requirement already satisfied: emoji==2.10.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (2.10.1)\n",
      "Requirement already satisfied: filetype==1.2.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: idna==3.6 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (3.6)\n",
      "Requirement already satisfied: joblib==1.3.2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (1.3.2)\n",
      "Requirement already satisfied: jsonpath-python==1.0.6 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (1.0.6)\n",
      "Requirement already satisfied: langdetect==1.0.9 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: lxml==5.1.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (5.1.0)\n",
      "Requirement already satisfied: marshmallow==3.20.2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (3.20.2)\n",
      "Requirement already satisfied: mypy-extensions==1.0.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (1.0.0)\n",
      "Requirement already satisfied: nltk==3.8.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: numpy==1.26.4 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (1.26.4)\n",
      "Requirement already satisfied: packaging==23.2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (23.2)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (2.8.2)\n",
      "Requirement already satisfied: python-iso639==2024.2.7 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (2024.2.7)\n",
      "Requirement already satisfied: python-magic==0.4.27 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: rapidfuzz==3.6.1 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (3.6.1)\n",
      "Requirement already satisfied: regex==2023.12.25 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (2023.12.25)\n",
      "Requirement already satisfied: requests==2.31.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: six==1.16.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (1.16.0)\n",
      "Requirement already satisfied: soupsieve==2.5 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (2.5)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: tqdm==4.66.2 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions==4.9.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (4.9.0)\n",
      "Requirement already satisfied: typing-inspect==0.9.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: unstructured-client==0.18.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (0.18.0)\n",
      "Requirement already satisfied: urllib3==1.26.18 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (1.26.18)\n",
      "Requirement already satisfied: wrapt==1.16.0 in /Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages (from unstructured) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install langchain==0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain. document_loaders import PyMuPDFLoader\n",
    "\n",
    "# nlp_docs = 'datasets/2_TextProc_2023.pdf'\n",
    "\n",
    "# loader = PyMuPDFLoader(nlp_docs)\n",
    "# documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple pdf\n",
    "\n",
    "import os\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# Path to the folder containing PDF documents\n",
    "folder_path = 'datasets'\n",
    "\n",
    "# Initialize an empty list to store loaded documents\n",
    "all_documents = []\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Check if the file is a PDF\n",
    "    if file_name.endswith('.pdf'):\n",
    "        # Construct the full path to the PDF file\n",
    "        pdf_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Load the PDF document\n",
    "        loader = PyMuPDFLoader(pdf_path)\n",
    "        documents = loader.load()\n",
    "        \n",
    "        # Add the loaded documents to the list\n",
    "        all_documents.extend(documents)\n",
    "\n",
    "# Now, all_documents contains the loaded documents from all PDFs in the \"datasets\" folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents\n",
    "# documents = all_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='      New Trends for Future Services \\nNext Generation Networks and Services \\nWireless Access and Transport Technologies\\nWireless Local Area and Personal Networks\\nService-oriented Computing\\nOptimisation: Theory and Network Applications\\nBusiness Modelling for Mobile Services \\nM.Sc. Thesis / Project\\nYEAR ONE\\nAIT, THAILAND\\nTelecommunication\\nComputer Science\\nInformation Management\\nInformation and Communication \\nTechnology\\nABOUT THE PROGRAM\\nCommunication Network and Services (ComNETS)\\nAIT and Telecom SudParis jointly offer a unique Euro-Asian curriculum at the master’s level \\naddressing key issues in communication networks and services in the European and Asian contexts.  \\nUpon successfully completing their studies in Asia and Europe, these students earn both an AIT \\nmaster’s degree and an MSc degree from Telecom SudParis (TSP).  Graduates are ready to apply \\ncutting-edge concepts and technologies in IT and the telecommunications industry.  Graduates of \\nthis programme have been employed equally in Europe, Asia and North America.\\nRegistration and Application:\\nApplicants shall register only both at:\\nAIT:. http://www.ait.ac.th/admissions/forms.html\\nand at \\nTSP:.http://www.telecom-sudparis.eu/p_en_formations-\\npost-grade_MSc_1179.html?idm=28 \\nApplicants have to register in one of four fields of study at \\nAIT:  Telecommunications, Information and Communication \\nTechnology, Computer Science, or Information Management\\nApplicants shall send an additional letter (to the AIT Admissions \\nUnit together with the other requested documents) stating \\nthat they wish to enroll in the dual Master’s degree AIT-TSP. \\nGeneral Requirements:\\nTo be eligible for admission to the Master’s \\nprogram, an applicant MUST: \\n1. Hold a Bachelor’s degree (normally from \\na four-year program), or its equivalent, in an \\nappropriate field of study from an institution of \\nrecognized standing;\\n2.  Have undergraduate grades significantly \\nabove average; the minimum GPA requirement \\nfor admission is 3 or equivalent at bachelor \\ndegree level;\\n3. Produce evidence of proficiency in English \\nin the form of an internationally recognized \\nstandardized test score; scores of 5 IELTS, 540 \\nat least TOEFL or 207 Computer TOEFL are \\naccepted; the requirement that a standardized \\ntest score be included in the applicant’s file can \\nbe waived if the applicant submits a certificate \\nconfirming that his/her previous degree was \\nearned at a university at which the sole medium \\nof instruction was English. Derogation rate: no \\nderogation will be accepted.\\nTuition fees:\\nThe first year’s tuition and registration fees of 376,000 Thai \\nbaht (approx. 12500 USD) are paid at AIT, and the second \\nyear’s tuition and registration fees of € 5.000 at TSP (1500€ \\nfor European). Additional costs include living expenses in \\nThailand and France as well as medical insurance and travel \\ncosts to both countries.\\nYEAR  TWO\\n         TELECOM SUD PARIS, \\nFRANCE\\n', metadata={'source': 'datasets/AIT_TSP.pdf', 'file_path': 'datasets/AIT_TSP.pdf', 'page': 3, 'total_pages': 4, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign CS5 (7.0)', 'producer': 'Adobe PDF Library 9.9', 'creationDate': \"D:20130410145137+07'00'\", 'modDate': \"D:20130410145140+07'00'\", 'trapped': ''})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Document Transformers\n",
    "\n",
    "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 700,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "\n",
    "doc = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='In their first year of study, students have the opportunity of entering \\none of four fields of study at AIT: Telecommunications, Information \\nand Communication Technology, Computer Science, or Information \\nManagement. In their second year at Telecom SudParis, they focus on \\nrecent evolution in Wireless Networks, Future Internet, Next Generation \\nNetworks and Services.', metadata={'source': 'datasets/AIT_TSP.pdf', 'file_path': 'datasets/AIT_TSP.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Adobe InDesign CS5 (7.0)', 'producer': 'Adobe PDF Library 9.9', 'creationDate': \"D:20130410145137+07'00'\", 'modDate': \"D:20130410145140+07'00'\", 'trapped': ''})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Text Embedding Models\n",
    "Embeddings create a vector representation of a piece of text. This is useful because it means we can think about text in the vector space, and do things like semantic search where we look for pieces of text that are most similar in the vector space.\n",
    "\n",
    "*Note* Instructor Model : [Huggingface](gingface.co/hkunlp/instructor-base) | [Paper](https://arxiv.org/abs/2212.09741)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_is_openai_v1' from 'langchain_community.embeddings.openai' (/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/langchain_community/embeddings/openai.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceInstructEmbeddings\n\u001b[1;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhkunlp/instructor-base\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m HuggingFaceInstructEmbeddings(\n\u001b[1;32m      7\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m model_name,\n\u001b[1;32m      8\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m : device}\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/langchain/embeddings/__init__.py:62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moctoai_embeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OctoAIEmbeddings\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mollama\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OllamaEmbeddings\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msagemaker_endpoint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SagemakerEndpointEmbeddings\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mself_hosted\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SelfHostedEmbeddings\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/langchain/embeddings/openai.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     OpenAIEmbeddings,\n\u001b[1;32m      3\u001b[0m     _async_retry_decorator,\n\u001b[1;32m      4\u001b[0m     _check_response,\n\u001b[1;32m      5\u001b[0m     _create_retry_decorator,\n\u001b[1;32m      6\u001b[0m     _is_openai_v1,\n\u001b[1;32m      7\u001b[0m     embed_with_retry,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_create_retry_decorator\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_async_retry_decorator\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAIEmbeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m ]\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_is_openai_v1' from 'langchain_community.embeddings.openai' (/Users/myothiha/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/langchain_community/embeddings/openai.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "model_name = 'hkunlp/instructor-base'\n",
    "\n",
    "embedding_model = HuggingFaceInstructEmbeddings(\n",
    "    model_name = model_name,\n",
    "    model_kwargs = {\"device\" : device}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Vector Stores\n",
    "\n",
    "One of the most common ways to store and search over unstructured data is to embed it and store the resulting embedding vectors, and then at query time to embed the unstructured query and retrieve the embedding vectors that are 'most similar' to the embedded query. A vector store takes care of storing embedded data and performing vector search for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create path done\n"
     ]
    }
   ],
   "source": [
    "#locate vectorstore\n",
    "vector_path = '../vector-store'\n",
    "if not os.path.exists(vector_path):\n",
    "    os.makedirs(vector_path)\n",
    "    print('create path done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#save vector locally\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[0;32m----> 4\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43membedding_model\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m db_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnlp_stanford\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m vectordb\u001b[38;5;241m.\u001b[39msave_local(\n\u001b[1;32m     12\u001b[0m     folder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(vector_path, db_file_name),\n\u001b[1;32m     13\u001b[0m     index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnlp\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#default index\u001b[39;00m\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/langchain_core/vectorstores.py:508\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    507\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/langchain_community/vectorstores/faiss.py:965\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    946\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[1;32m    947\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \n\u001b[1;32m    949\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 965\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[1;32m    967\u001b[0m         texts,\n\u001b[1;32m    968\u001b[0m         embeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    973\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/langchain_community/embeddings/huggingface.py:174\u001b[0m, in \u001b[0;36mHuggingFaceInstructEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute doc embeddings using a HuggingFace instruct model.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    173\u001b[0m instruction_pairs \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_instruction, text] \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[0;32m--> 174\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstruction_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/InstructorEmbedding/instructor.py:539\u001b[0m, in \u001b[0;36mINSTRUCTOR.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    536\u001b[0m features \u001b[38;5;241m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 539\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    542\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/InstructorEmbedding/instructor.py:269\u001b[0m, in \u001b[0;36mINSTRUCTOR_Transformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext_masks\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    268\u001b[0m     context_masks \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext_masks\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 269\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    271\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1975\u001b[0m, in \u001b[0;36mT5EncoderModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m   1959\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;124;03m>>> last_hidden_states = outputs.last_hidden_state\u001b[39;00m\n\u001b[1;32m   1972\u001b[0m \u001b[38;5;124;03m```\"\"\"\u001b[39;00m\n\u001b[1;32m   1973\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1975\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1976\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1978\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1980\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1981\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1983\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoder_outputs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1110\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1096\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1097\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         output_attentions,\n\u001b[1;32m   1108\u001b[0m     )\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1110\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:754\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    751\u001b[0m     attention_outputs \u001b[38;5;241m=\u001b[39m attention_outputs \u001b[38;5;241m+\u001b[39m cross_attention_outputs[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# Apply Feed Forward layer\u001b[39;00m\n\u001b[0;32m--> 754\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:343\u001b[0m, in \u001b[0;36mT5LayerFF.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m    342\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 343\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDenseReluDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforwarded_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(forwarded_states)\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:288\u001b[0m, in \u001b[0;36mT5DenseActDense.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[0;32m--> 288\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(hidden_states)\n\u001b[1;32m    290\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP_Datacamp/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#save vector locally\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.from_documents(\n",
    "    documents = doc,\n",
    "    embedding = embedding_model\n",
    ")\n",
    "\n",
    "db_file_name = 'nlp_stanford'\n",
    "\n",
    "vectordb.save_local(\n",
    "    folder_path = os.path.join(vector_path, db_file_name),\n",
    "    index_name = 'nlp' #default index\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 retrievers\n",
    "A retriever is an interface that returns documents given an unstructured query. It is more general than a vector store. A retriever does not need to be able to store documents, only to return (or retrieve) them. Vector stores can be used as the backbone of a retriever, but there are other types of retrievers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling vector from local\n",
    "vector_path = '../vector-store'\n",
    "db_file_name = 'nlp_stanford'\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.load_local(\n",
    "    folder_path = os.path.join(vector_path, db_file_name),\n",
    "    embeddings = embedding_model,\n",
    "    index_name = 'nlp' #default index\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ready to use\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='for projective dependency parsing.\\nProceedings of the 8th International\\nWorkshop on Parsing Technologies\\n(IWPT).\\nNivre, J. 2006. Inductive Dependency\\nParsing. Springer.\\nNivre, J. 2009.\\nNon-projective de-\\npendency parsing in expected linear\\ntime. ACL IJCNLP.', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 614, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       " Document(page_content='dependency parse; the internal structure of the dependency parse consists solely of\\ndirected relations between words. These head-dependent relationships directly en-\\ncode important information that is often buried in the more complex phrase-structure\\nparses. For example, the arguments to the verb prefer are directly linked to it in the\\ndependency structure, while their connection to the main verb is more distant in the\\nphrase-structure tree. Similarly, morning and Denver, modiﬁers of ﬂight, are linked\\nto it directly in the dependency structure. This fact that the head-dependent rela-\\ntions are a good proxy for the semantic relationship between predicates and their', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 388, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       " Document(page_content='CHAPTER\\n18\\nDependency Parsing\\nThe focus of the last chapter was on context-free grammars and constituent-based\\nrepresentations. Here we present another important family of grammar formalisms\\ncalled dependency grammars. In dependency formalisms, phrasal constituents and\\ndependency\\ngrammars\\nphrase-structure rules do not play a direct role. Instead, the syntactic structure of a\\nsentence is described solely in terms of directed binary grammatical relations be-\\ntween the words, as in the following dependency parse:\\nI prefer the morning ﬂight through Denver\\nnsubj\\nobj\\ndet\\nnmod\\nnmod\\ncase\\nroot\\n(18.1)\\nRelations among the words are illustrated above the sentence with directed, labeled', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 388, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       " Document(page_content='404\\nCHAPTER 18\\n•\\nDEPENDENCY PARSING\\nChoi et al. (2015) presents a performance analysis of 10 dependency parsers across\\na range of metrics, as well as DEPENDABLE, a robust parser evaluation tool.\\nExercises', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 411, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"What is Dependency Parsing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='formers are not based on recurrent connections (which can be hard to parallelize),\\nwhich means that transformers can be more efﬁcient to implement at scale.\\nTransformers map sequences of input vectors (x1,...,xn) to sequences of output\\nvectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\\nformer blocks, each of which is a multilayer network made by combining simple\\nlinear layers, feedforward networks, and self-attention layers, the key innovation of\\nself-attention\\ntransformers. Self-attention allows a network to directly extract and use information\\nfrom arbitrarily large contexts without the need to pass it through intermediate re-', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       " Document(page_content='multaneously. For example, distinct syntactic, semantic, and discourse relationships\\ncan hold between verbs and their arguments in a sentence. It would be difﬁcult for\\na single transformer block to learn to capture all of the different kinds of parallel\\nrelations among its inputs. Transformers address this issue with multihead self-\\nattention layers. These are sets of self-attention layers, called heads, that reside in\\nmultihead\\nself-attention\\nlayers\\nparallel layers at the same depth in a model, each with its own set of parameters.', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 224, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       " Document(page_content='214\\nCHAPTER 10\\n•\\nTRANSFORMERS AND PRETRAINED LANGUAGE MODELS\\n• As the current focus of attention when being compared to all of the other\\npreceding inputs. We’ll refer to this role as a query.\\nquery\\n• In its role as a preceding input being compared to the current focus of atten-\\ntion. We’ll refer to this role as a key.\\nkey\\n• And ﬁnally, as a value used to compute the output for the current focus of\\nvalue\\nattention.\\nTo capture these three different roles, transformers introduce weight matrices\\nWQ, WK, and WV. These weights will be used to project each input vector xi into\\na representation of its role as a key, query, or value.\\nqi = WQxi; ki = WKxi; vi = WVxi\\n(10.5)', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 221, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       " Document(page_content='transformer\\nThe transformer offers new mechanisms (self-attention and positional encod-\\nings) that help represent time and help focus on how words relate to each other over\\nlong distances. We’ll see how to apply this model to the task of language modeling,\\nand then we’ll see how a transformer pretrained on language modeling can be used\\nin a zero shot manner to perform other NLP tasks.\\n10.1\\nSelf-Attention Networks: Transformers\\nIn this section we introduce the architecture of transformers. Like the LSTMs of\\ntransformers\\nChapter 9, transformers can handle distant information. But unlike LSTMs, trans-\\nformers are not based on recurrent connections (which can be hard to parallelize),', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"What is Transformers\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Memory\n",
    "\n",
    "One of the core utility classes underpinning most (if not all) memory modules is the ChatMessageHistory class. This is a super lightweight wrapper that provides convenience methods for saving HumanMessages, AIMessages, and then fetching them all.\n",
    "\n",
    "You may want to use this class directly if you are managing memory outside of a chain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_user_message('hi')\n",
    "history.add_ai_message('Whats up?')\n",
    "history.add_user_message('How are you')\n",
    "history.add_ai_message('I\\'m quite good. How about you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[HumanMessage(content='hi'), AIMessage(content='Whats up?'), HumanMessage(content='How are you'), AIMessage(content=\"I'm quite good. How about you?\")])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Memory types\n",
    "\n",
    "There are many different types of memory. Each has their own parameters, their own return types, and is useful in different scenarios. \n",
    "- Converstaion Buffer\n",
    "- Converstaion Buffer Window"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What variables get returned from memory\n",
    "\n",
    "Before going into the chain, various variables are read from memory. These have specific names which need to align with the variables the chain expects. You can see what these variables are by calling memory.load_memory_variables({}). Note that the empty dictionary that we pass in is just a placeholder for real variables. If the memory type you are using is dependent upon the input variables, you may need to pass some in."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, you can see that load_memory_variables returns a single key, history. This means that your chain (and likely your prompt) should expect an input named history. You can usually control this variable through parameters on the memory class. For example, if you want the memory variables to be returned in the key chat_history you can do:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converstaion Buffer\n",
    "This memory allows for storing messages and then extracts the messages in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: hi\\nAI: What's up?\\nHuman: How are you?\\nAI: I'm quite good. How about you?\"}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
    "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='hi'),\n",
       "  AIMessage(content=\"What's up?\"),\n",
       "  HumanMessage(content='How are you?'),\n",
       "  AIMessage(content=\"I'm quite good. How about you?\")]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages = True)\n",
    "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
    "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversation Buffer Window\n",
    "- it keeps a list of the interactions of the conversation over time. \n",
    "- it only uses the last K interactions. \n",
    "- it can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: How are you?\\nAI: I'm quite good. How about you?\"}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
    "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chain\n",
    "\n",
    "Using an LLM in isolation is fine for simple applications, but more complex applications require chaining LLMs - either with each other or with other components.\n",
    "\n",
    "An `LLMChain` is a simple chain that adds some functionality around language models.\n",
    "- it consists of a `PromptTemplate` and a `LM` (either an LLM or chat model).\n",
    "- it formats the prompt template using the input key values provided (and also memory key values, if available), \n",
    "- it passes the formatted string to LLM and returns the LLM output.\n",
    "\n",
    "Note : [Download Fastchat Model Here](https://huggingface.co/lmsys/fastchat-t5-3b-v1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ./models\n",
    "# !git clone https://huggingface.co/lmsys/fastchat-t5-3b-v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 14:57:27.374664: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-02 14:57:27.392320: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-02 14:57:27.392344: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-02 14:57:27.392979: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-02 14:57:27.396491: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-02 14:57:27.688556: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline, AutoModelForSeq2SeqLM\n",
    "from transformers import BitsAndBytesConfig\n",
    "from langchain import HuggingFacePipeline\n",
    "import torch\n",
    "\n",
    "model_id = '../models/fastchat-t5-3b-v1.0/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "bitsandbyte_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype = torch.float16,\n",
    "    bnb_4bit_use_double_quant = True\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config = bitsandbyte_config, #caution Nvidia\n",
    "    device_map = 'auto',\n",
    "    load_in_8bit = True\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens = 256,\n",
    "    model_kwargs = {\n",
    "        \"temperature\" : 0,\n",
    "        \"repetition_penalty\": 1.5\n",
    "    }\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline = pipe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Class ConversationalRetrievalChain](https://api.python.langchain.com/en/latest/_modules/langchain/chains/conversational_retrieval/base.html#ConversationalRetrievalChain)\n",
    "\n",
    "- `retriever` : Retriever to use to fetch documents.\n",
    "\n",
    "- `combine_docs_chain` : The chain used to combine any retrieved documents.\n",
    "\n",
    "- `question_generator`: The chain used to generate a new question for the sake of retrieval. This chain will take in the current question (with variable question) and any chat history (with variable chat_history) and will produce a new standalone question to be used later on.\n",
    "\n",
    "- `return_source_documents` : Return the retrieved source documents as part of the final result.\n",
    "\n",
    "- `get_chat_history` : An optional function to get a string of the chat history. If None is provided, will use a default.\n",
    "\n",
    "- `return_generated_question` : Return the generated question as part of the final result.\n",
    "\n",
    "- `response_if_no_docs_found` : If specified, the chain will return a fixed response if no docs are found for the question.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`question_generator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['chat_history', 'question'], template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONDENSE_QUESTION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generator = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = CONDENSE_QUESTION_PROMPT,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "Human:What is Machine Learning\n",
      "AI:\n",
      "Human:What is Deep Learning\n",
      "AI:\n",
      "Follow Up Input: Comparing Both of them\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': 'Human:What is Machine Learning\\nAI:\\nHuman:What is Deep Learning\\nAI:',\n",
       " 'question': 'Comparing Both of them',\n",
       " 'text': '<pad> What  is  the  difference  between  Machine  Learning  and  Deep  Learning  AI?\\n'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Comparing both of them'\n",
    "chat_history = \"Human:What is Machine Learning\\nAI:\\nHuman:What is Deep Learning\\nAI:\"\n",
    "\n",
    "question_generator({'chat_history' : chat_history, \"question\" : query})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`combine_docs_chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], template=\"I'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \\n    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it's about probabilistic models, language models, or any other related topic, \\n    I'm here to help break down complex concepts into easy-to-understand explanations.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x7fefa8f7ec50>)), document_variable_name='context')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_chain = load_qa_chain(\n",
    "    llm = llm,\n",
    "    chain_type = 'stuff',\n",
    "    prompt = PROMPT,\n",
    "    verbose = True\n",
    ")\n",
    "doc_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \n",
      "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
      "    Whether it's about probabilistic models, language models, or any other related topic, \n",
      "    I'm here to help break down complex concepts into easy-to-understand explanations.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    formers are not based on recurrent connections (which can be hard to parallelize),\n",
      "which means that transformers can be more efﬁcient to implement at scale.\n",
      "Transformers map sequences of input vectors (x1,...,xn) to sequences of output\n",
      "vectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\n",
      "former blocks, each of which is a multilayer network made by combining simple\n",
      "linear layers, feedforward networks, and self-attention layers, the key innovation of\n",
      "self-attention\n",
      "transformers. Self-attention allows a network to directly extract and use information\n",
      "from arbitrarily large contexts without the need to pass it through intermediate re-\n",
      "\n",
      "multaneously. For example, distinct syntactic, semantic, and discourse relationships\n",
      "can hold between verbs and their arguments in a sentence. It would be difﬁcult for\n",
      "a single transformer block to learn to capture all of the different kinds of parallel\n",
      "relations among its inputs. Transformers address this issue with multihead self-\n",
      "attention layers. These are sets of self-attention layers, called heads, that reside in\n",
      "multihead\n",
      "self-attention\n",
      "layers\n",
      "parallel layers at the same depth in a model, each with its own set of parameters.\n",
      "\n",
      "214\n",
      "CHAPTER 10\n",
      "•\n",
      "TRANSFORMERS AND PRETRAINED LANGUAGE MODELS\n",
      "• As the current focus of attention when being compared to all of the other\n",
      "preceding inputs. We’ll refer to this role as a query.\n",
      "query\n",
      "• In its role as a preceding input being compared to the current focus of atten-\n",
      "tion. We’ll refer to this role as a key.\n",
      "key\n",
      "• And ﬁnally, as a value used to compute the output for the current focus of\n",
      "value\n",
      "attention.\n",
      "To capture these three different roles, transformers introduce weight matrices\n",
      "WQ, WK, and WV. These weights will be used to project each input vector xi into\n",
      "a representation of its role as a key, query, or value.\n",
      "qi = WQxi; ki = WKxi; vi = WVxi\n",
      "(10.5)\n",
      "\n",
      "transformer\n",
      "The transformer offers new mechanisms (self-attention and positional encod-\n",
      "ings) that help represent time and help focus on how words relate to each other over\n",
      "long distances. We’ll see how to apply this model to the task of language modeling,\n",
      "and then we’ll see how a transformer pretrained on language modeling can be used\n",
      "in a zero shot manner to perform other NLP tasks.\n",
      "10.1\n",
      "Self-Attention Networks: Transformers\n",
      "In this section we introduce the architecture of transformers. Like the LSTMs of\n",
      "transformers\n",
      "Chapter 9, transformers can handle distant information. But unlike LSTMs, trans-\n",
      "formers are not based on recurrent connections (which can be hard to parallelize),\n",
      "    Question: What is Transformers?\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='formers are not based on recurrent connections (which can be hard to parallelize),\\nwhich means that transformers can be more efﬁcient to implement at scale.\\nTransformers map sequences of input vectors (x1,...,xn) to sequences of output\\nvectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\\nformer blocks, each of which is a multilayer network made by combining simple\\nlinear layers, feedforward networks, and self-attention layers, the key innovation of\\nself-attention\\ntransformers. Self-attention allows a network to directly extract and use information\\nfrom arbitrarily large contexts without the need to pass it through intermediate re-', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='multaneously. For example, distinct syntactic, semantic, and discourse relationships\\ncan hold between verbs and their arguments in a sentence. It would be difﬁcult for\\na single transformer block to learn to capture all of the different kinds of parallel\\nrelations among its inputs. Transformers address this issue with multihead self-\\nattention layers. These are sets of self-attention layers, called heads, that reside in\\nmultihead\\nself-attention\\nlayers\\nparallel layers at the same depth in a model, each with its own set of parameters.', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 224, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='214\\nCHAPTER 10\\n•\\nTRANSFORMERS AND PRETRAINED LANGUAGE MODELS\\n• As the current focus of attention when being compared to all of the other\\npreceding inputs. We’ll refer to this role as a query.\\nquery\\n• In its role as a preceding input being compared to the current focus of atten-\\ntion. We’ll refer to this role as a key.\\nkey\\n• And ﬁnally, as a value used to compute the output for the current focus of\\nvalue\\nattention.\\nTo capture these three different roles, transformers introduce weight matrices\\nWQ, WK, and WV. These weights will be used to project each input vector xi into\\na representation of its role as a key, query, or value.\\nqi = WQxi; ki = WKxi; vi = WVxi\\n(10.5)', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 221, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='transformer\\nThe transformer offers new mechanisms (self-attention and positional encod-\\nings) that help represent time and help focus on how words relate to each other over\\nlong distances. We’ll see how to apply this model to the task of language modeling,\\nand then we’ll see how a transformer pretrained on language modeling can be used\\nin a zero shot manner to perform other NLP tasks.\\n10.1\\nSelf-Attention Networks: Transformers\\nIn this section we introduce the architecture of transformers. Like the LSTMs of\\ntransformers\\nChapter 9, transformers can handle distant information. But unlike LSTMs, trans-\\nformers are not based on recurrent connections (which can be hard to parallelize),', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})],\n",
       " 'question': 'What is Transformers?',\n",
       " 'output_text': '<pad>  A  type  of  neural  network  architecture  that  maps  sequences  of  input  vectors  (x1,...,xn)  to  sequences  of  output  vectors  (y1,...,yn)  of  the  same  length.  Transformers  are  made  up  of  stacks  of  trans-\\n'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is Transformers?\"\n",
    "input_document = retriever.get_relevant_documents(query)\n",
    "\n",
    "doc_chain({'input_documents':input_document, 'question':query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationalRetrievalChain(memory=ConversationBufferWindowMemory(output_key='answer', return_messages=True, memory_key='chat_history', k=3), verbose=True, combine_docs_chain=StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], template=\"I'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \\n    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it's about probabilistic models, language models, or any other related topic, \\n    I'm here to help break down complex concepts into easy-to-understand explanations.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x7fefa8f7ec50>)), document_variable_name='context'), question_generator=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['chat_history', 'question'], template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x7fefa8f7ec50>)), return_source_documents=True, get_chat_history=<function <lambda> at 0x7fef45fef400>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceInstructEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7fefaad30b50>))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    k=3, \n",
    "    memory_key = \"chat_history\",\n",
    "    return_messages = True,\n",
    "    output_key = 'answer'\n",
    ")\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=retriever,\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents=True,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    get_chat_history=lambda h : h\n",
    ")\n",
    "chain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \n",
      "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
      "    Whether it's about probabilistic models, language models, or any other related topic, \n",
      "    I'm here to help break down complex concepts into easy-to-understand explanations.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    in this way are also called complementizers.\n",
      "complementizer\n",
      "Pronouns act as a shorthand for referring to an entity or event. Personal pro-\n",
      "pronoun\n",
      "nouns refer to persons or entities (you, she, I, it, me, etc.). Possessive pronouns are\n",
      "forms of personal pronouns that indicate either actual possession or more often just\n",
      "an abstract relation between the person and some object (my, your, his, her, its, one’s,\n",
      "our, their). Wh-pronouns (what, who, whom, whoever) are used in certain question\n",
      "wh\n",
      "\n",
      "EXERCISES\n",
      "57\n",
      "<s> I am Sam </s>\n",
      "<s> Sam I am </s>\n",
      "<s> I am Sam </s>\n",
      "<s> I do not like green eggs and Sam </s>\n",
      "Using a bigram language model with add-one smoothing, what is P(Sam |\n",
      "am)? Include <s> and </s> in your counts just like any other token.\n",
      "3.5\n",
      "Suppose we didn’t use the end-symbol </s>. Train an unsmoothed bigram\n",
      "grammar on the following training corpus without using the end-symbol </s>:\n",
      "<s> a b\n",
      "<s> b b\n",
      "<s> b a\n",
      "<s> a a\n",
      "Demonstrate that your bigram model does not assign a single probability dis-\n",
      "tribution across all sentence lengths by showing that the sum of the probability\n",
      "of the four possible 2 word sentences over the alphabet {a,b} is 1.0, and the\n",
      "\n",
      "through two millennia speaks to their centrality in models of human language.\n",
      "Proper names are another important and anciently studied linguistic category.\n",
      "While parts of speech are generally assigned to individual words or morphemes, a\n",
      "proper name is often an entire multiword phrase, like the name “Marie Curie”, the\n",
      "location “New York City”, or the organization “Stanford University”. We’ll use the\n",
      "term named entity for, roughly speaking, anything that can be referred to with a\n",
      "named entity\n",
      "proper name: a person, a location, an organization, although as we’ll see the term is\n",
      "commonly extended to include things that aren’t entities per se.\n",
      "\n",
      "15.2\n",
      "•\n",
      "CHATBOTS\n",
      "303\n",
      "Men are all alike.\n",
      "IN WHAT WAY\n",
      "They’re always bugging us about something or other.\n",
      "CAN YOU THINK OF A SPECIFIC EXAMPLE\n",
      "Well my boyfriend made me come here.\n",
      "YOUR BOYFRIEND MADE YOU COME HERE\n",
      "He says I’m depressed much of the time.\n",
      "I AM SORRY TO HEAR YOU ARE DEPRESSED\n",
      "....\n",
      "WHO ELSE IN YOUR FAMILY TAKES CARE OF YOU?\n",
      "My father\n",
      "YOUR FATHER\n",
      "You are like my father in some ways.\n",
      "WHAT RESEMBLANCE DO YOU SEE\n",
      "You are not very aggressive but I think you don’t want me to notice that.\n",
      "WHAT MAKES YOU THINK I AM NOT AGGRESSIVE\n",
      "You don’t argue with me.\n",
      "WHY DO YOU THINK I DON’T ARGUE WITH YOU\n",
      "You are afraid of me.\n",
      "DOES IT PLEASE YOU TO BELIEVE I’M AFRAID OF YOU\n",
      "    Question: Who are you by the way?\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Who are you by the way?',\n",
       " 'chat_history': [],\n",
       " 'answer': '<pad>  I  am  Chaky.\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include`< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.6\\n Suppose  we  didn’t  use  the  end-symbol  .  Train  an  unsmoothed  bigram  grammar  on  the  following  training  corpus  without  using  the  end-symbol:\\n< s>\\n I  do  not  like  green  eggs  and  Sam\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include{< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.7\\n Suppose  we  didn’t  use  the  end-symbol  .  Train ',\n",
       " 'source_documents': [Document(page_content='in this way are also called complementizers.\\ncomplementizer\\nPronouns act as a shorthand for referring to an entity or event. Personal pro-\\npronoun\\nnouns refer to persons or entities (you, she, I, it, me, etc.). Possessive pronouns are\\nforms of personal pronouns that indicate either actual possession or more often just\\nan abstract relation between the person and some object (my, your, his, her, its, one’s,\\nour, their). Wh-pronouns (what, who, whom, whoever) are used in certain question\\nwh', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 169, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='EXERCISES\\n57\\n<s> I am Sam </s>\\n<s> Sam I am </s>\\n<s> I am Sam </s>\\n<s> I do not like green eggs and Sam </s>\\nUsing a bigram language model with add-one smoothing, what is P(Sam |\\nam)? Include <s> and </s> in your counts just like any other token.\\n3.5\\nSuppose we didn’t use the end-symbol </s>. Train an unsmoothed bigram\\ngrammar on the following training corpus without using the end-symbol </s>:\\n<s> a b\\n<s> b b\\n<s> b a\\n<s> a a\\nDemonstrate that your bigram model does not assign a single probability dis-\\ntribution across all sentence lengths by showing that the sum of the probability\\nof the four possible 2 word sentences over the alphabet {a,b} is 1.0, and the', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 64, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='through two millennia speaks to their centrality in models of human language.\\nProper names are another important and anciently studied linguistic category.\\nWhile parts of speech are generally assigned to individual words or morphemes, a\\nproper name is often an entire multiword phrase, like the name “Marie Curie”, the\\nlocation “New York City”, or the organization “Stanford University”. We’ll use the\\nterm named entity for, roughly speaking, anything that can be referred to with a\\nnamed entity\\nproper name: a person, a location, an organization, although as we’ll see the term is\\ncommonly extended to include things that aren’t entities per se.', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 167, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='15.2\\n•\\nCHATBOTS\\n303\\nMen are all alike.\\nIN WHAT WAY\\nThey’re always bugging us about something or other.\\nCAN YOU THINK OF A SPECIFIC EXAMPLE\\nWell my boyfriend made me come here.\\nYOUR BOYFRIEND MADE YOU COME HERE\\nHe says I’m depressed much of the time.\\nI AM SORRY TO HEAR YOU ARE DEPRESSED\\n....\\nWHO ELSE IN YOUR FAMILY TAKES CARE OF YOU?\\nMy father\\nYOUR FATHER\\nYou are like my father in some ways.\\nWHAT RESEMBLANCE DO YOU SEE\\nYou are not very aggressive but I think you don’t want me to notice that.\\nWHAT MAKES YOU THINK I AM NOT AGGRESSIVE\\nYou don’t argue with me.\\nWHY DO YOU THINK I DON’T ARGUE WITH YOU\\nYou are afraid of me.\\nDOES IT PLEASE YOU TO BELIEVE I’M AFRAID OF YOU', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 310, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_question = \"Who are you by the way?\"\n",
    "answer = chain({\"question\":prompt_question})\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content='Who are you by the way?'), AIMessage(content='<pad>  I  am  Chaky.\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include`< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.6\\n Suppose  we  didn’t  use  the  end-symbol  .  Train  an  unsmoothed  bigram  grammar  on  the  following  training  corpus  without  using  the  end-symbol:\\n< s>\\n I  do  not  like  green  eggs  and  Sam\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include{< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.7\\n Suppose  we  didn’t  use  the  end-symbol  .  Train ')]\n",
      "Follow Up Input: What is the Transformers?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \n",
      "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
      "    Whether it's about probabilistic models, language models, or any other related topic, \n",
      "    I'm here to help break down complex concepts into easy-to-understand explanations.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    formers are not based on recurrent connections (which can be hard to parallelize),\n",
      "which means that transformers can be more efﬁcient to implement at scale.\n",
      "Transformers map sequences of input vectors (x1,...,xn) to sequences of output\n",
      "vectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\n",
      "former blocks, each of which is a multilayer network made by combining simple\n",
      "linear layers, feedforward networks, and self-attention layers, the key innovation of\n",
      "self-attention\n",
      "transformers. Self-attention allows a network to directly extract and use information\n",
      "from arbitrarily large contexts without the need to pass it through intermediate re-\n",
      "\n",
      "multaneously. For example, distinct syntactic, semantic, and discourse relationships\n",
      "can hold between verbs and their arguments in a sentence. It would be difﬁcult for\n",
      "a single transformer block to learn to capture all of the different kinds of parallel\n",
      "relations among its inputs. Transformers address this issue with multihead self-\n",
      "attention layers. These are sets of self-attention layers, called heads, that reside in\n",
      "multihead\n",
      "self-attention\n",
      "layers\n",
      "parallel layers at the same depth in a model, each with its own set of parameters.\n",
      "\n",
      "transformer\n",
      "The transformer offers new mechanisms (self-attention and positional encod-\n",
      "ings) that help represent time and help focus on how words relate to each other over\n",
      "long distances. We’ll see how to apply this model to the task of language modeling,\n",
      "and then we’ll see how a transformer pretrained on language modeling can be used\n",
      "in a zero shot manner to perform other NLP tasks.\n",
      "10.1\n",
      "Self-Attention Networks: Transformers\n",
      "In this section we introduce the architecture of transformers. Like the LSTMs of\n",
      "transformers\n",
      "Chapter 9, transformers can handle distant information. But unlike LSTMs, trans-\n",
      "formers are not based on recurrent connections (which can be hard to parallelize),\n",
      "\n",
      "214\n",
      "CHAPTER 10\n",
      "•\n",
      "TRANSFORMERS AND PRETRAINED LANGUAGE MODELS\n",
      "• As the current focus of attention when being compared to all of the other\n",
      "preceding inputs. We’ll refer to this role as a query.\n",
      "query\n",
      "• In its role as a preceding input being compared to the current focus of atten-\n",
      "tion. We’ll refer to this role as a key.\n",
      "key\n",
      "• And ﬁnally, as a value used to compute the output for the current focus of\n",
      "value\n",
      "attention.\n",
      "To capture these three different roles, transformers introduce weight matrices\n",
      "WQ, WK, and WV. These weights will be used to project each input vector xi into\n",
      "a representation of its role as a key, query, or value.\n",
      "qi = WQxi; ki = WKxi; vi = WVxi\n",
      "(10.5)\n",
      "    Question: <pad> What  is  the  Transformers?\n",
      "\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the Transformers?',\n",
       " 'chat_history': [HumanMessage(content='Who are you by the way?'),\n",
       "  AIMessage(content='<pad>  I  am  Chaky.\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include`< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.6\\n Suppose  we  didn’t  use  the  end-symbol  .  Train  an  unsmoothed  bigram  grammar  on  the  following  training  corpus  without  using  the  end-symbol:\\n< s>\\n I  do  not  like  green  eggs  and  Sam\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include{< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.7\\n Suppose  we  didn’t  use  the  end-symbol  .  Train ')],\n",
       " 'answer': '<pad>  transformers  are  a  type  of  neural  network  that  are  used  to  map  sequences  of  input  vectors  (x1,...,xn)  to  sequences  of  output  vectors  (y1,...,yn)  of  the  same  length.  They  are  made  up  of  stacks  of  transformer  blocks,  each  of  which  is  a  multilayer  network  made  by  combining  simple  linear  layers,  feedforward  networks,  and  self-attention  layers,  the  key  innovation  of  self-attention  transformers.  Self-attention  allows  a  network  to  directly  extract  and  use  information  from  arbitrarily  large  contexts  without  the  need  to  pass  it  through  intermediate  re-\\n multaneously.  For  example,  distinct  syntactic,  semantic,  and  discourse  relationships  can  hold  between  verbs  and  their  arguments  in ',\n",
       " 'source_documents': [Document(page_content='formers are not based on recurrent connections (which can be hard to parallelize),\\nwhich means that transformers can be more efﬁcient to implement at scale.\\nTransformers map sequences of input vectors (x1,...,xn) to sequences of output\\nvectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\\nformer blocks, each of which is a multilayer network made by combining simple\\nlinear layers, feedforward networks, and self-attention layers, the key innovation of\\nself-attention\\ntransformers. Self-attention allows a network to directly extract and use information\\nfrom arbitrarily large contexts without the need to pass it through intermediate re-', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='multaneously. For example, distinct syntactic, semantic, and discourse relationships\\ncan hold between verbs and their arguments in a sentence. It would be difﬁcult for\\na single transformer block to learn to capture all of the different kinds of parallel\\nrelations among its inputs. Transformers address this issue with multihead self-\\nattention layers. These are sets of self-attention layers, called heads, that reside in\\nmultihead\\nself-attention\\nlayers\\nparallel layers at the same depth in a model, each with its own set of parameters.', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 224, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='transformer\\nThe transformer offers new mechanisms (self-attention and positional encod-\\nings) that help represent time and help focus on how words relate to each other over\\nlong distances. We’ll see how to apply this model to the task of language modeling,\\nand then we’ll see how a transformer pretrained on language modeling can be used\\nin a zero shot manner to perform other NLP tasks.\\n10.1\\nSelf-Attention Networks: Transformers\\nIn this section we introduce the architecture of transformers. Like the LSTMs of\\ntransformers\\nChapter 9, transformers can handle distant information. But unlike LSTMs, trans-\\nformers are not based on recurrent connections (which can be hard to parallelize),', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='214\\nCHAPTER 10\\n•\\nTRANSFORMERS AND PRETRAINED LANGUAGE MODELS\\n• As the current focus of attention when being compared to all of the other\\npreceding inputs. We’ll refer to this role as a query.\\nquery\\n• In its role as a preceding input being compared to the current focus of atten-\\ntion. We’ll refer to this role as a key.\\nkey\\n• And ﬁnally, as a value used to compute the output for the current focus of\\nvalue\\nattention.\\nTo capture these three different roles, transformers introduce weight matrices\\nWQ, WK, and WV. These weights will be used to project each input vector xi into\\na representation of its role as a key, query, or value.\\nqi = WQxi; ki = WKxi; vi = WVxi\\n(10.5)', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 221, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_question = \"What is the Transformers?\"\n",
    "answer = chain({\"question\":prompt_question})\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content='Who are you by the way?'), AIMessage(content='<pad>  I  am  Chaky.\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include`< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.6\\n Suppose  we  didn’t  use  the  end-symbol  .  Train  an  unsmoothed  bigram  grammar  on  the  following  training  corpus  without  using  the  end-symbol:\\n< s>\\n I  do  not  like  green  eggs  and  Sam\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include{< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.7\\n Suppose  we  didn’t  use  the  end-symbol  .  Train '), HumanMessage(content='What is the Transformers?'), AIMessage(content='<pad>  transformers  are  a  type  of  neural  network  that  are  used  to  map  sequences  of  input  vectors  (x1,...,xn)  to  sequences  of  output  vectors  (y1,...,yn)  of  the  same  length.  They  are  made  up  of  stacks  of  transformer  blocks,  each  of  which  is  a  multilayer  network  made  by  combining  simple  linear  layers,  feedforward  networks,  and  self-attention  layers,  the  key  innovation  of  self-attention  transformers.  Self-attention  allows  a  network  to  directly  extract  and  use  information  from  arbitrarily  large  contexts  without  the  need  to  pass  it  through  intermediate  re-\\n multaneously.  For  example,  distinct  syntactic,  semantic,  and  discourse  relationships  can  hold  between  verbs  and  their  arguments  in ')]\n",
      "Follow Up Input: Is it a statistical model?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \n",
      "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
      "    Whether it's about probabilistic models, language models, or any other related topic, \n",
      "    I'm here to help break down complex concepts into easy-to-understand explanations.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    sequence, i.e. the target string with the highest probability. Fig. 10.8 demonstrates\n",
      "the problem, using a made-up example. Notice that the most probable sequence is\n",
      "ok ok </s> (with a probability of .4*.7*1.0), but a greedy search algorithm will fail\n",
      "to ﬁnd it, because it incorrectly chooses yes as the ﬁrst word since it has the highest\n",
      "local probability.\n",
      "start\n",
      "ok\n",
      "yes\n",
      "</s>\n",
      "ok\n",
      "yes\n",
      "</s>\n",
      "ok\n",
      "yes\n",
      "</s>\n",
      "</s>\n",
      "</s>\n",
      "</s>\n",
      "</s>\n",
      "t2\n",
      "t3\n",
      "p(t1|start)\n",
      "t1\n",
      "p(t2| t1)\n",
      "p(t3| t1,t2)\n",
      ".1\n",
      ".5\n",
      ".4\n",
      ".2\n",
      ".4\n",
      ".3\n",
      ".1\n",
      ".2\n",
      ".7\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "Figure 10.8\n",
      "A search tree for generating the target string T = t1,t2,... from the vocabulary\n",
      "V = {yes,ok,<s>}, showing the probability of generating each token from that state. Greedy\n",
      "\n",
      "formers are not based on recurrent connections (which can be hard to parallelize),\n",
      "which means that transformers can be more efﬁcient to implement at scale.\n",
      "Transformers map sequences of input vectors (x1,...,xn) to sequences of output\n",
      "vectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\n",
      "former blocks, each of which is a multilayer network made by combining simple\n",
      "linear layers, feedforward networks, and self-attention layers, the key innovation of\n",
      "self-attention\n",
      "transformers. Self-attention allows a network to directly extract and use information\n",
      "from arbitrarily large contexts without the need to pass it through intermediate re-\n",
      "\n",
      "214\n",
      "CHAPTER 10\n",
      "•\n",
      "TRANSFORMERS AND PRETRAINED LANGUAGE MODELS\n",
      "• As the current focus of attention when being compared to all of the other\n",
      "preceding inputs. We’ll refer to this role as a query.\n",
      "query\n",
      "• In its role as a preceding input being compared to the current focus of atten-\n",
      "tion. We’ll refer to this role as a key.\n",
      "key\n",
      "• And ﬁnally, as a value used to compute the output for the current focus of\n",
      "value\n",
      "attention.\n",
      "To capture these three different roles, transformers introduce weight matrices\n",
      "WQ, WK, and WV. These weights will be used to project each input vector xi into\n",
      "a representation of its role as a key, query, or value.\n",
      "qi = WQxi; ki = WKxi; vi = WVxi\n",
      "(10.5)\n",
      "\n",
      "dictates the complexity of model. Both the time and memory requirements in a\n",
      "transformer grow quadratically with the length of the input. It’s necessary, therefore,\n",
      "to set a ﬁxed input length that is long enough to provide sufﬁcient context for the\n",
      "    Question: <pad>  Is  the  Transformers  a  statistical  model?\n",
      "\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Is it a statistical model?',\n",
       " 'chat_history': [HumanMessage(content='Who are you by the way?'),\n",
       "  AIMessage(content='<pad>  I  am  Chaky.\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include`< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.6\\n Suppose  we  didn’t  use  the  end-symbol  .  Train  an  unsmoothed  bigram  grammar  on  the  following  training  corpus  without  using  the  end-symbol:\\n< s>\\n I  do  not  like  green  eggs  and  Sam\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include{< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.7\\n Suppose  we  didn’t  use  the  end-symbol  .  Train '),\n",
       "  HumanMessage(content='What is the Transformers?'),\n",
       "  AIMessage(content='<pad>  transformers  are  a  type  of  neural  network  that  are  used  to  map  sequences  of  input  vectors  (x1,...,xn)  to  sequences  of  output  vectors  (y1,...,yn)  of  the  same  length.  They  are  made  up  of  stacks  of  transformer  blocks,  each  of  which  is  a  multilayer  network  made  by  combining  simple  linear  layers,  feedforward  networks,  and  self-attention  layers,  the  key  innovation  of  self-attention  transformers.  Self-attention  allows  a  network  to  directly  extract  and  use  information  from  arbitrarily  large  contexts  without  the  need  to  pass  it  through  intermediate  re-\\n multaneously.  For  example,  distinct  syntactic,  semantic,  and  discourse  relationships  can  hold  between  verbs  and  their  arguments  in ')],\n",
       " 'answer': '<pad> Yes,  transformers  are  a  statistical  model  that  use  probability  to  learn  the  relationships  between  input  and  output  vectors.  They  are  based  on  the  idea  that  the  input  vectors  are  a  sequence  of  probabilities,  and  that  the  output  vectors  are  a  sequence  of  probabilities  that  are  a  product  of  the  input  vectors.  This  allows  the  model  to  learn  the  relationships  between  input  and  output  vectors  by  comparing  the  probabilities  of  the  input  vectors  to  the  probabilities  of  the  output  vectors.\\n',\n",
       " 'source_documents': [Document(page_content='sequence, i.e. the target string with the highest probability. Fig. 10.8 demonstrates\\nthe problem, using a made-up example. Notice that the most probable sequence is\\nok ok </s> (with a probability of .4*.7*1.0), but a greedy search algorithm will fail\\nto ﬁnd it, because it incorrectly chooses yes as the ﬁrst word since it has the highest\\nlocal probability.\\nstart\\nok\\nyes\\n</s>\\nok\\nyes\\n</s>\\nok\\nyes\\n</s>\\n</s>\\n</s>\\n</s>\\n</s>\\nt2\\nt3\\np(t1|start)\\nt1\\np(t2| t1)\\np(t3| t1,t2)\\n.1\\n.5\\n.4\\n.2\\n.4\\n.3\\n.1\\n.2\\n.7\\n1.0\\n1.0\\n1.0\\n1.0\\nFigure 10.8\\nA search tree for generating the target string T = t1,t2,... from the vocabulary\\nV = {yes,ok,<s>}, showing the probability of generating each token from that state. Greedy', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 229, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='formers are not based on recurrent connections (which can be hard to parallelize),\\nwhich means that transformers can be more efﬁcient to implement at scale.\\nTransformers map sequences of input vectors (x1,...,xn) to sequences of output\\nvectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\\nformer blocks, each of which is a multilayer network made by combining simple\\nlinear layers, feedforward networks, and self-attention layers, the key innovation of\\nself-attention\\ntransformers. Self-attention allows a network to directly extract and use information\\nfrom arbitrarily large contexts without the need to pass it through intermediate re-', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='214\\nCHAPTER 10\\n•\\nTRANSFORMERS AND PRETRAINED LANGUAGE MODELS\\n• As the current focus of attention when being compared to all of the other\\npreceding inputs. We’ll refer to this role as a query.\\nquery\\n• In its role as a preceding input being compared to the current focus of atten-\\ntion. We’ll refer to this role as a key.\\nkey\\n• And ﬁnally, as a value used to compute the output for the current focus of\\nvalue\\nattention.\\nTo capture these three different roles, transformers introduce weight matrices\\nWQ, WK, and WV. These weights will be used to project each input vector xi into\\na representation of its role as a key, query, or value.\\nqi = WQxi; ki = WKxi; vi = WVxi\\n(10.5)', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 221, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='dictates the complexity of model. Both the time and memory requirements in a\\ntransformer grow quadratically with the length of the input. It’s necessary, therefore,\\nto set a ﬁxed input length that is long enough to provide sufﬁcient context for the', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 238, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_question = \"Is it a statistical model?\"\n",
    "answer = chain({\"question\":prompt_question})\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
